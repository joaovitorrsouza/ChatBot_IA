# ðŸ¤– Chatbot com Python, FastAPI, Docker e OpenAI

Este projeto Ã© uma API de chatbot desenvolvida em **Python** com **FastAPI**, utilizando a API da **OpenAI (GPT-3.5-turbo)** para gerar respostas inteligentes a mensagens recebidas. Toda a aplicaÃ§Ã£o Ã© containerizada com **Docker**, facilitando o deploy em qualquer ambiente.

---

## ðŸ“Œ Funcionalidades

- Envio de mensagens via requisiÃ§Ã£o HTTP `POST`  
- Respostas geradas dinamicamente por inteligÃªncia artificial  
- CÃ³digo limpo e modular  
- Docker para execuÃ§Ã£o em ambientes isolados  
- Pronto para deploy em nuvem ou local  

---

## ðŸ§° Tecnologias utilizadas

- Python 3.10+  
- FastAPI  
- OpenAI Python SDK (>= 1.0)  
- Uvicorn (servidor ASGI)  
- Docker  

---

## ðŸš€ Como executar o projeto

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/chatbot-ia.git
cd chatbot-ia
```

### 2. Configure a chave da API da OpenAI

Crie uma conta em:  
https://platform.openai.com/account/api-keys

Depois, crie um arquivo `.env` no diretÃ³rio raiz com o seguinte conteÃºdo:

```
OPENAI_API_KEY=sua-chave-aqui
```

Substitua `sua-chave-aqui` pela sua chave real.

---

### 3. Construa a imagem Docker

Com o Docker instalado e rodando, execute:

```bash
docker build -t chatbot-ia .
```

---

### 4. Execute o container

```bash
docker run -p 8000:8000 --env-file .env chatbot-ia
```

A API estarÃ¡ disponÃ­vel em:  
http://localhost:8000

---

## ðŸ“¡ Como testar a API

### Endpoint: `POST /chat`

**RequisiÃ§Ã£o:**

```json
{
  "prompt": "OlÃ¡, tudo bem?"
}
```

**Resposta esperada:**

```json
{
  "response": "OlÃ¡! Estou aqui para te ajudar. Em que posso ser Ãºtil hoje?"
}
```

---

## ðŸ”¬ Exemplos de testes

### Usando `curl`:

```bash
curl -X POST http://localhost:8000/chat   -H "Content-Type: application/json"   -d "{"prompt":"OlÃ¡, tudo bem?"}"
```

### Usando Postman ou Insomnia:

- MÃ©todo: `POST`  
- URL: `http://localhost:8000/chat`  
- Body (raw JSON):

```json
{
  "prompt": "OlÃ¡, tudo bem?"
}
```


---

## ðŸ“„ Dockerfile utilizado

```Dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

## ðŸ§  Sobre a API da OpenAI

Este projeto utiliza o modelo **gpt-3.5-turbo** da OpenAI para gerar respostas inteligentes e contextuais.  
DocumentaÃ§Ã£o oficial: https://platform.openai.com/docs


## âœ… Melhorias futuras

- [ ] Interface Web (ex: Streamlit ou React)  
- [ ] AutenticaÃ§Ã£o com JWT  
- [ ] Registro de logs de conversas  
- [ ] Limite de uso por IP ou chave  

---
